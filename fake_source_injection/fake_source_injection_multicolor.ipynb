{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ce4a79-6afd-4306-937d-5acad040ad1a",
   "metadata": {},
   "source": [
    "# Injecting and Measuring Artificial Stars in Single-Visit Images\n",
    "\n",
    "Jeff Carlin <br>\n",
    "Last verified to run Monday, April 26, 2022, with weekly 2022_12.\n",
    "\n",
    "This tutorial demonstrates a method to inject artificial stars into `calexp` images using the measured point-spread function of the given `calexp` image. It then shows how to run the pipelines' detection and measurement tasks on these images, extract the measurements of the artificial stars, and compare their measured magnitudes to the input (simulated) magnitudes.\n",
    "\n",
    "#### Prerequisites\n",
    "\n",
    "This tutorial assumes familiarity with afwDisplay, the Butler, and source detection with the LSST Science Pipelines.\n",
    "Relevant tutorials can be found in the <a href=\"https://github.com/rubin-dp0/tutorial-notebooks\">rubin-dp0/tutorial-notebooks</a> repository.\n",
    "(For image display, see NBs 03a, 03b, and 08a; for the Butler, see NB 04; and for source detection, see NB 05).\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial shows a way to use existing tools in the LSST Science Pipelines to inject artificial stars into processed single-visit images (\"calexps\"), then run the detection and measurement tasks to test the recovery of these stars and their (known) properties. In this particular notebook, the focus is on inserting _stars_ into the images because that is the simplest operation (requiring only a position and a flux/magnitude). However, the tools do exist to insert simulated galaxies (based on parameters describing their light distribution), or to insert images (for example, an image of a simulated galaxy cluster) into processed data. See <a href=\"https://community.lsst.org/t/new-tasks-for-fake-source-insertion/3722\">this post</a> on the Community forum for an introduction to the current fake source injection tasks.\n",
    "\n",
    "**NOTE**: The task that is used in this notebook to create fake stars will soon be deprecated and removed from the Science Pipelines, and its replacement tasks (discussed in the Community forum post linked above) will also soon be replaced with refactored and improved tasks. Once the new synthetic source code has arrived, this notebook should be updated to use the newer tasks.\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e40a8ba-393d-45a2-bb2a-ebfbb03c514e",
   "metadata": {},
   "source": [
    "The workflow in this notebook is as follows:\n",
    "\n",
    "1. Starting with an RA, Dec position, find all single-visit images that overlap that position.\n",
    "    - (For this tutorisal, we select only a single visit image from each band.)\n",
    "2. Given positions and input magnitudes for fake stars (in _ugri_ bands), figure out what the X, Y positions and fluxes should be in each image.\n",
    "3. Inject those stars into the appropriate images with the X, Y positions and fluxes as calculated in the previous step, using the measured PSF for each individual image to create stellar images.\n",
    "4. Run all processing steps (characterization, calibration, detection, deblending, measurement) on each image that fake stars were inserted into.\n",
    "5. Compare the measured positions and fluxes/mags to the input synthetic values.\n",
    "\n",
    "## Set Up\n",
    "\n",
    "#### Import packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42187a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import IFrame, display, Markdown\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.patches import Rectangle\n",
    "from astropy.visualization import ZScaleInterval\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9fbfe1-296c-4980-80c0-4b2b8efca6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tasks from the LSST Science Pipelines for reprocessing images\n",
    "from lsst.pipe.tasks.characterizeImage import CharacterizeImageTask\n",
    "from lsst.pipe.tasks.calibrate import CalibrateTask\n",
    "from lsst.meas.algorithms.detection import SourceDetectionTask\n",
    "from lsst.meas.deblender import SourceDeblendTask\n",
    "from lsst.meas.base import SingleFrameMeasurementTask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0868985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LSST Science Pipelines packages (see pipelines.lsst.io)\n",
    "import lsst.daf.base as dafBase\n",
    "from lsst.daf.butler import Butler\n",
    "import lsst.afw.image as afwImage\n",
    "import lsst.afw.display as afwDisplay\n",
    "import lsst.afw.table as afwTable\n",
    "import lsst.geom as geom\n",
    "import lsst.pipe.tasks.fakes as fakes\n",
    "\n",
    "# Use lsst.afw.display with the matplotlib backend\n",
    "afwDisplay.setDefaultBackend('matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8094618-1aef-4e41-b8e6-992aecbe5961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some plotting defaults:\n",
    "\n",
    "params = {'axes.labelsize': 28,\n",
    "          'font.size': 24,\n",
    "          'legend.fontsize': 14,\n",
    "          'xtick.major.width': 3,\n",
    "          'xtick.minor.width': 2,\n",
    "          'xtick.major.size': 12,\n",
    "          'xtick.minor.size': 6,\n",
    "          'xtick.direction': 'in',\n",
    "          'xtick.top': True,\n",
    "          'lines.linewidth': 3,\n",
    "          'axes.linewidth': 3,\n",
    "          'axes.labelweight': 3,\n",
    "          'axes.titleweight': 3,\n",
    "          'ytick.major.width': 3,\n",
    "          'ytick.minor.width': 2,\n",
    "          'ytick.major.size': 12,\n",
    "          'ytick.minor.size': 6,\n",
    "          'ytick.direction': 'in',\n",
    "          'ytick.right': True,\n",
    "          'figure.figsize': [9, 9],\n",
    "          'figure.facecolor': 'White'\n",
    "          }\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8c5bae-55da-4046-867d-e6f84d72bfff",
   "metadata": {},
   "source": [
    "#### Instantiate the Butler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3251edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For DC2 gen3, these are the only optoins\n",
    "repo = 's3://butler-us-central1-dp01'\n",
    "collection = '2.2i/runs/DP0.1'\n",
    "\n",
    "butler = Butler(repo, collections=collection)\n",
    "registry = butler.registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e038f66-74cc-4f50-a9ef-99d5d6963e82",
   "metadata": {},
   "source": [
    "#### Create a list of artificial stars to inject: \n",
    "\n",
    "To inject artificial stars, all that is needed is a list of RA, Dec positions, and magnitudes to assign the simulated stars.\n",
    "\n",
    "We will generate `nfakes` stars with positions randomly distributed (using a normal distribution of size `scatter_arcmin` in arcminutes) about the center coordinate (racen, deccen). The stars will be evenly spaced in u-band magnitude (i.e., in `nfakes` equal intervals between magmin and magmax), and randomly distributed about a mean color for each band. (I chose to use a fixed mean color for all stars for simplicity, but apply a normally-distributed scatter of `mag_scatter` magnitudes about this mean value so they are not all identical.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697dad31-9de9-411a-94b2-9cb59a429ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Central (RA, Dec) position (in degrees) at which to insert stars:\n",
    "racen = 70.376995\n",
    "deccen = -37.175736\n",
    "\n",
    "# Place all the fake stars within `scatter_arcmin` arcminutes of the center coordinate:\n",
    "scatter_arcmin = 1.0\n",
    "\n",
    "# \"nfakes\" is the number of fake stars to inject:\n",
    "nfakes = 31\n",
    "\n",
    "# Assign positions using a (random) normal distribution about the center coordinates:\n",
    "fake_ras = racen + (np.random.randn(nfakes) * scatter_arcmin / 60.0)\n",
    "fake_decs = deccen + (np.random.randn(nfakes) * scatter_arcmin / 60.0)\n",
    "\n",
    "# Make artificial u magnitudes in a range:\n",
    "min_umag = 18.0\n",
    "max_umag = 22.0\n",
    "mag_scatter = 0.3\n",
    "fake_umags = np.linspace(min_umag, max_umag, nfakes)\n",
    "\n",
    "# Now assign magnitudes in other bands using (~fixed) colors:\n",
    "fake_gmags = fake_umags - (1.0 + mag_scatter * np.random.randn(nfakes))  # distrib centered on u-g=1.0\n",
    "fake_rmags = fake_gmags - (0.4 + mag_scatter * np.random.randn(nfakes))  # distrib centered on g-r=0.4\n",
    "fake_imags = fake_rmags - (0.2 + mag_scatter * np.random.randn(nfakes))  # distrib centered on r-i=0.2\n",
    "\n",
    "# These are totally arbitrary colors, but should be kinda similar to BHB stars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab2c0ec-ecf5-4131-bb8b-52e27daa0ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(fake_ras, fake_decs, fake_gmags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8523f75d-5b8c-4b84-89e0-22fabd2f9d7e",
   "metadata": {},
   "source": [
    "### Look up the images that overlap the desired coordinates\n",
    "\n",
    "We will use the spatial query method introduced in [notebook 04: Intro to the Butler](https://github.com/rubin-dp0/tutorial-notebooks/blob/main/04_Intro_to_Butler.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebeca84-1d38-409b-8525-3e8bb5e0c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.sphgeom\n",
    "\n",
    "pixelization = lsst.sphgeom.HtmPixelization(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202ca902-361f-4feb-853b-e665cb0d2951",
   "metadata": {},
   "outputs": [],
   "source": [
    "htm_id = pixelization.index(\n",
    "    lsst.sphgeom.UnitVector3d(\n",
    "        lsst.sphgeom.LonLat.fromDegrees(racen, deccen)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Obtain and print the scale to provide a sense of the size of the sky pixelization being used\n",
    "scale = pixelization.triangle(htm_id).getBoundingCircle().getOpeningAngle().asDegrees()*3600\n",
    "print(f'HTM ID={htm_id} at level={pixelization.getLevel()} is a ~{scale:0.2}\" triangle.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3484fb71-9939-4ce7-b345-be7f804d50c7",
   "metadata": {},
   "source": [
    "#### Now query the registry for all \"calexp\" images overlapping the desired position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c7be4-a872-44a4-98d9-24e6f8f7a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetRefs = registry.queryDatasets(\"calexp\", htm20=htm_id)\n",
    "\n",
    "print(\"Found \", datasetRefs.count(), \" calexps at that position.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c975f67-11de-4165-8dbb-898ea6c7a49b",
   "metadata": {
    "tags": []
   },
   "source": [
    "That's nice, but it finds images from all bands overlapping the position in a single iterator. Let's get lists separately for each band:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ecb201-a53b-4c25-80e8-cee0ea43a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetRefs_u = registry.queryDatasets(\"calexp\", htm20=htm_id, band=\"u\")\n",
    "datasetRefs_g = registry.queryDatasets(\"calexp\", htm20=htm_id, band=\"g\")\n",
    "datasetRefs_r = registry.queryDatasets(\"calexp\", htm20=htm_id, band=\"r\")\n",
    "datasetRefs_i = registry.queryDatasets(\"calexp\", htm20=htm_id, band=\"i\")\n",
    "\n",
    "print(\"Found \", datasetRefs_u.count(), \" u-band calexps at that position.\")\n",
    "print(\"Found \", datasetRefs_g.count(), \" g-band calexps at that position.\")\n",
    "print(\"Found \", datasetRefs_r.count(), \" r-band calexps at that position.\")\n",
    "print(\"Found \", datasetRefs_i.count(), \" i-band calexps at that position.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4371855-afdb-48d2-a129-79cb9baf1a1f",
   "metadata": {},
   "source": [
    "For now, let's just grab the first image in the list for each band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66283e9-99c7-43b2-abb6-71b2b220217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ref in enumerate(datasetRefs_u):\n",
    "    uref = ref\n",
    "    if i > 0:\n",
    "        break\n",
    "\n",
    "for i, ref in enumerate(datasetRefs_g):\n",
    "    gref = ref\n",
    "    if i > 0:\n",
    "        break\n",
    "\n",
    "for i, ref in enumerate(datasetRefs_r):\n",
    "    rref = ref\n",
    "    if i > 0:\n",
    "        break\n",
    "\n",
    "for i, ref in enumerate(datasetRefs_i):\n",
    "    iref = ref\n",
    "    if i > 0:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ea6f09-1bf9-45c1-9b9b-2fa45e2b49a0",
   "metadata": {},
   "source": [
    "What does that `datasetRef` object look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28369ab2-97bc-4a7e-99e7-50eb45335b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iref"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373b3c73",
   "metadata": {},
   "source": [
    "### Make stars and inject them into images:\n",
    "\n",
    "First, write a function (\"makeFakeStar\") that takes as inputs the position, flux (intensity), and the PSF, and returns an image of the PSF scaled to the desired flux at the input position.\n",
    "\n",
    "Next, we add a function (\"addFakeStars\") that takes the list of RAs, Decs, and magnitudes, and a `datasetRef` for a `calexp` image, and returns a version of the input `calexp` that has the fake stars injected into it. (This function calls \"makeFakeStar\" for each star in the list.)\n",
    "\n",
    "The source injection steps were developed following this piece of code as an example: https://github.com/lsst/pipe_tasks/blob/387f8f07a2b66205f9fa6bda9a89dcdbbef3f64c/tests/test_fakeProcessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa8aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make stars at a given position with a given intensity\n",
    "def makeFakeStar(position, intensity, psf):\n",
    "    psfImage = psf.computeImage(geom.Point2D(position.x, position.y)).getArray()\n",
    "    psfImage *= intensity\n",
    "    noise = np.random.normal(0, np.sqrt(abs(psfImage)))\n",
    "    return psfImage + noise, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac55d1f-ce5c-4e71-aaa1-2c0c5632493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addFakeStars(ras, decs, mags, calexp_ref):\n",
    "    calexp_inp = butler.get('calexp', calexp_ref.dataId)\n",
    "    calexp_withFakes = calexp_inp.clone()\n",
    "\n",
    "    # Fetch objects from the exposure\n",
    "    psf = calexp_withFakes.getPsf()\n",
    "    image = calexp_withFakes.getMaskedImage().getImage()\n",
    "    mask = calexp_withFakes.getMaskedImage().getMask()\n",
    "    variance = calexp_withFakes.getMaskedImage().getVariance()\n",
    "    wcs = calexp_withFakes.getWcs()\n",
    "    photocalib = calexp_withFakes.getPhotoCalib()\n",
    "\n",
    "    fluxes = []\n",
    "\n",
    "    # Use the \"photocalib\" from the calexp to convert magnitudes to instrumental fluxes:\n",
    "    for mag in mags:\n",
    "        fluxes.append(photocalib.magnitudeToInstFlux(mag))\n",
    "\n",
    "    # Get the corner coordinates of the image:\n",
    "    y0 = image.getY0()\n",
    "    x0 = image.getX0()\n",
    "    ymax = y0+calexp_withFakes.getDimensions()[0]\n",
    "    xmax = x0+calexp_withFakes.getDimensions()[1]\n",
    "    \n",
    "    # Bitplane to set corresponding to the FAKE bit\n",
    "    # fakeMaskValue = 2**mask.getMaskPlaneDict()['FAKE']\n",
    "    fakeMaskValue = 2**12\n",
    "    \n",
    "    #xvals = []\n",
    "    #yvals = []\n",
    "    \n",
    "    # At each position create a star with the given intensity and add it\n",
    "    # to the image.\n",
    "    for ra, dec, intensity in zip(ras, decs, fluxes):\n",
    "        # Use the WCS to convert RA, Dec to X, Y pixel coordinates:\n",
    "        pixcoord = wcs.skyToPixel(geom.SpherePoint(ra, dec, geom.degrees))\n",
    "        pos = positionTuple(pixcoord.y, pixcoord.x)\n",
    "        #xvals.append(pos.x)\n",
    "        #yvals.append(pos.y)\n",
    "\n",
    "        # Call \"makeFakeStar\" to get the image of a PSF-like object with the desired flux:\n",
    "        objArray, noiseArray = makeFakeStar(pos, intensity, psf)\n",
    "        psfRad = int((objArray.shape[0]-1)/2.)\n",
    "\n",
    "        # Check that the desired position is within the image:\n",
    "        oky = (pos.y > psfRad/2) & (pos.y < ymax - psfRad/2)\n",
    "        okx = (pos.x > psfRad/2) & (pos.x < xmax - psfRad/2)\n",
    "\n",
    "        if okx & oky:\n",
    "            yslice = slice(int(np.floor(pos.y - psfRad - y0)), int(np.floor(pos.y + psfRad + y0 + 1)))\n",
    "            xslice = slice(int(np.floor(pos.x - psfRad - x0)), int(np.floor(pos.x + psfRad + x0 + 1)))\n",
    "\n",
    "            print('Injecting source at y, x = ', pos.y, pos.x)\n",
    "\n",
    "            image.getArray()[yslice, xslice] += objArray\n",
    "            mask.getArray()[yslice, xslice] += fakeMaskValue\n",
    "            variance.getArray()[yslice, xslice] += noiseArray**2\n",
    "        else:\n",
    "            print('Skipped injecting source at y, x = ', pos.y, pos.x, ' because it is too close to (or off) the edge.')\n",
    "\n",
    "    return calexp_inp, calexp_withFakes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e78af4-6f87-453f-8391-2a4a845ef433",
   "metadata": {},
   "source": [
    "### Call the \"addFakeStars\" function to create calexp images with the artificial stars injected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898f7dae-fdf3-4c75-b16b-59f8fba70cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "calexp_orig_u, calexp_new_u = addFakeStars(fake_ras, fake_decs, fake_umags, uref)\n",
    "calexp_orig_g, calexp_new_g = addFakeStars(fake_ras, fake_decs, fake_gmags, gref)\n",
    "calexp_orig_r, calexp_new_r = addFakeStars(fake_ras, fake_decs, fake_rmags, rref)\n",
    "calexp_orig_i, calexp_new_i = addFakeStars(fake_ras, fake_decs, fake_imags, iref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05a2147-24d6-42f1-82bd-5ef64c55d452",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Wrap all of the detection and measurement steps in a function.\n",
    "\n",
    "The steps here follow the <a href=\"https://github.com/rubin-dp0/tutorial-notebooks/blob/main/05_Intro_to_Source_Detection.ipynb\">Intro to Source Detection</a> tutorial notebook, so rather than explain them in detail here, we simply wrap all the steps in a single function that can be executed for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd528c4-80e3-404f-b277-1d7c5f6d2065",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processFakes(calexp_inp):\n",
    "    \n",
    "    # Create a basic schema to use with these tasks\n",
    "    schema = afwTable.SourceTable.makeMinimalSchema()\n",
    "\n",
    "    # Create a container which will be used to record metadata about algorithm execution\n",
    "    algMetadata = dafBase.PropertyList()\n",
    "\n",
    "    # Initialize CharacterizeImageTask and its configuration:\n",
    "    config = CharacterizeImageTask.ConfigClass()\n",
    "    config.psfIterations = 1\n",
    "    charImageTask = CharacterizeImageTask(None, config=config)\n",
    "\n",
    "    # Initialize SourceDetectionTask and its configuration:\n",
    "    config = SourceDetectionTask.ConfigClass()\n",
    "    config.thresholdValue = 10      # detection threshold in units of thresholdType\n",
    "    config.thresholdType = \"stdev\"   # units for thresholdValue\n",
    "    sourceDetectionTask = SourceDetectionTask(schema=schema, config=config)\n",
    "    sourceDeblendTask = SourceDeblendTask(schema=schema)\n",
    "\n",
    "    # Initialize SingleFrameMeasurementTask and its configuration:\n",
    "    config = SingleFrameMeasurementTask.ConfigClass()\n",
    "    sourceMeasurementTask = SingleFrameMeasurementTask(schema=schema, config=config, algMetadata=algMetadata)\n",
    "\n",
    "    # Make an empty table that we'll put the results in:\n",
    "    tab = afwTable.SourceTable.make(schema)\n",
    "    \n",
    "    # Image characterization\n",
    "    result = charImageTask.run(calexp_inp)\n",
    "\n",
    "    # Get the PSF and some image properties\n",
    "    psf = calexp_inp.getPsf()\n",
    "    sigma = psf.computeShape().getDeterminantRadius()\n",
    "    pixelScale = calexp_inp.getWcs().getPixelScale().asArcseconds()\n",
    "\n",
    "    # The factor of 2.355 converts from std to fwhm\n",
    "    print('psf fwhm = {:.2f} arcsec'.format(sigma*pixelScale*2.355))\n",
    "    \n",
    "    # Run source detection\n",
    "    result = sourceDetectionTask.run(tab, calexp_inp)\n",
    "    \n",
    "    sources = result.sources\n",
    "    \n",
    "    # Run source deblending\n",
    "    sourceDeblendTask.run(calexp_inp, sources)\n",
    "\n",
    "    # Run source measurement\n",
    "    sourceMeasurementTask.run(measCat=sources, exposure=calexp_inp)\n",
    "\n",
    "    # The copy makes sure that the sources are sequential in memory\n",
    "    sources = sources.copy(True)\n",
    "    \n",
    "    # For convenience, return an Astropy table:\n",
    "    source_tab = sources.asAstropy()\n",
    "    \n",
    "    # Convert fluxes to magnitudes and add them to the table\n",
    "    photocalib = calexp_inp.getPhotoCalib()\n",
    "    psfmags = photocalib.instFluxToMagnitude(sources, 'base_PsfFlux')\n",
    "    source_tab.add_columns([psfmags[:,0], psfmags[:,1]], names=['mag_psf', 'magerr_psf'])\n",
    "    \n",
    "    return(source_tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fd9490-5b58-4799-9987-785583ab97c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run the \"processFakes\" function on each image that we injected fake stars into\n",
    "\n",
    "**This may take at least a couple minutes to run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee54085-8f58-4ecc-bb17-67ae4016ac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "\n",
    "sources_withfakes_u = processFakes(calexp_new_u)\n",
    "sources_withfakes_g = processFakes(calexp_new_g)\n",
    "sources_withfakes_r = processFakes(calexp_new_r)\n",
    "sources_withfakes_i = processFakes(calexp_new_i)\n",
    "\n",
    "t2 = time.time()\n",
    "print('dt', t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b88d6c-d908-4a5f-96ee-64be2d9bbf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the catalog:\n",
    "\n",
    "sources_withfakes_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f9835-4e2f-4759-8a6d-ad331c339f2d",
   "metadata": {},
   "source": [
    "### Match coordinates from the original list of fake stars to the new catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905764b9-0ed9-4975-a4a7-b40511acb0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates of input fake stars\n",
    "sc_fakes = SkyCoord(ra=fake_ras*u.deg, dec=fake_decs*u.deg, frame='icrs')\n",
    "\n",
    "# Coordinates of objects in calexps with fakes added:\n",
    "sc_withfakes_u = SkyCoord(ra=sources_withfakes_u['coord_ra'], dec=sources_withfakes_u['coord_dec'], frame='icrs')\n",
    "sc_withfakes_g = SkyCoord(ra=sources_withfakes_g['coord_ra'], dec=sources_withfakes_g['coord_dec'], frame='icrs')\n",
    "sc_withfakes_r = SkyCoord(ra=sources_withfakes_r['coord_ra'], dec=sources_withfakes_r['coord_dec'], frame='icrs')\n",
    "sc_withfakes_i = SkyCoord(ra=sources_withfakes_i['coord_ra'], dec=sources_withfakes_i['coord_dec'], frame='icrs')\n",
    "# Note that units weren't required for sc_withfakes_*, because it already has them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b89df62-46fb-493d-8b09-c1eee98980d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match them using the Astropy SkyCoord \"match_to_catalog_sky\" method:\n",
    "\n",
    "idx_u, sep_u, _ = sc_fakes.match_to_catalog_sky(sc_withfakes_u)\n",
    "idx_g, sep_g, _ = sc_fakes.match_to_catalog_sky(sc_withfakes_g)\n",
    "idx_r, sep_r, _ = sc_fakes.match_to_catalog_sky(sc_withfakes_r)\n",
    "idx_i, sep_i, _ = sc_fakes.match_to_catalog_sky(sc_withfakes_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dbd3a2-c12e-456c-b6d8-9929bb809aa9",
   "metadata": {},
   "source": [
    "The \"idx*\" arrays are the indices into sc_withfakes* files to extract the closest match, and \"sep*\" are the actual separations between the sources. Note that this returns a separation for all objects -- in the following, we will keep only sources with match separations less than 1 arcsecond (i.e., \"good\" matches).\n",
    "\n",
    "Extract info about the good matches into arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94319b0-0943-4099-a222-e47d8e2297a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "okmch_u = (sep_u.arcsec < 1.0)\n",
    "mch_mags_u = sources_withfakes_u[idx_u]['mag_psf']\n",
    "mch_magerrs_u = sources_withfakes_u[idx_u]['magerr_psf']\n",
    "# If the nearest match is >1\" away, set its magnitudes to -99.9:\n",
    "mch_mags_u[~okmch_u] = -99.9\n",
    "mch_magerrs_u[~okmch_u] = 99.9\n",
    "seps_u = sep_u.arcsec\n",
    "\n",
    "okmch_g = (sep_g.arcsec < 1.0)\n",
    "mch_mags_g = sources_withfakes_g[idx_g]['mag_psf']\n",
    "mch_magerrs_g = sources_withfakes_g[idx_g]['magerr_psf']\n",
    "mch_mags_g[~okmch_g] = -99.9\n",
    "mch_magerrs_g[~okmch_g] = 99.9\n",
    "seps_g = sep_g.arcsec\n",
    "\n",
    "okmch_r = (sep_r.arcsec < 1.0)\n",
    "mch_mags_r = sources_withfakes_r[idx_r]['mag_psf']\n",
    "mch_magerrs_r = sources_withfakes_r[idx_r]['magerr_psf']\n",
    "mch_mags_r[~okmch_r] = -99.9\n",
    "mch_magerrs_r[~okmch_r] = 99.9\n",
    "seps_r = sep_r.arcsec\n",
    "\n",
    "okmch_i = (sep_i.arcsec < 1.0)\n",
    "mch_mags_i = sources_withfakes_i[idx_i]['mag_psf']\n",
    "mch_magerrs_i = sources_withfakes_i[idx_i]['magerr_psf']\n",
    "mch_mags_i[~okmch_i] = -99.9\n",
    "mch_magerrs_i[~okmch_i] = 99.9\n",
    "seps_i = sep_i.arcsec\n",
    "\n",
    "#print(fake_imags[okmch], sources_withfakes_i[idx_i[okmch]]['mag_psf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94695591-aff0-4688-b7fd-5e5e9303fe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sep_i.arcsec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e023c05a-6b9f-4bea-8a0b-d83190d24fa0",
   "metadata": {},
   "source": [
    "Combine all of the information into a single table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77edcf9-0c9e-4434-b8b7-c0de6352fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_all = Table([fake_ras, fake_decs, fake_umags, fake_gmags, fake_rmags, fake_imags,\n",
    "                 mch_mags_u, mch_magerrs_u, seps_u, mch_mags_g, mch_magerrs_g, seps_g,\n",
    "                 mch_mags_r, mch_magerrs_r, seps_r, mch_mags_i, mch_magerrs_i, seps_i],\n",
    "                 names=['ra', 'dec', 'u_fake', 'g_fake', 'r_fake', 'i_fake', 'u_meas', 'uerr_meas', 'sep_u',\n",
    "                        'g_meas', 'gerr_meas', 'sep_g', 'r_meas', 'rerr_meas', 'sep_r',\n",
    "                        'i_meas', 'ierr_meas', 'sep_i'],\n",
    "                 units=[u.deg, u.deg, u.mag, u.mag, u.mag, u.mag, u.mag, u.mag, u.arcsec,\n",
    "                        u.mag, u.mag, u.arcsec, u.mag, u.mag, u.arcsec, u.mag, u.mag, u.arcsec])\n",
    "\n",
    "for col in tab_all.colnames[0:2]:\n",
    "    tab_all[col].info.format = '%.8g'  # for consistent table output\n",
    "for col in tab_all.colnames[2:]:\n",
    "    tab_all[col].info.format = '%.5g'  # for consistent table output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd44c12-74b0-4eb5-b2e7-1862aa9cec4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec21cf5-5603-49da-a5c7-d4b9a0046719",
   "metadata": {},
   "source": [
    "Now we have completed all the steps of injecting fake sources, running pipeline tasks to detect and measure all sources in the resulting images, and extracting the matches from the catalogs. Let's look at the results!\n",
    "\n",
    "Compare the \"fake\" magnitudes we assigned to each star to their output (measured) magnitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e32d786-b71a-4323-afca-4b9f77ddccb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.plot(figsize=(9, 9))\n",
    "\n",
    "plt.hlines(0, 0, 30, linestyle=':', color='Black')\n",
    "plt.plot(tab_all['u_fake'], 1000.0 * (tab_all['u_meas'] - tab_all['u_fake']),\n",
    "         'o', ms=10, color='royalblue', label='u')\n",
    "plt.plot(tab_all['g_fake'], 1000.0 * (tab_all['g_meas'] - tab_all['g_fake']),\n",
    "         'D', ms=10, color='mediumseagreen', label='g')\n",
    "plt.plot(tab_all['r_fake'], 1000.0 * (tab_all['r_meas'] - tab_all['r_fake']),\n",
    "         '*', ms=10, color='firebrick', label='r')\n",
    "plt.plot(tab_all['i_fake'], 1000.0 * (tab_all['i_meas'] - tab_all['i_fake']),\n",
    "         's', ms=10, color='indigo', label='i')\n",
    "plt.legend()\n",
    "plt.xlabel(r'$mag_{\\rm fake}$')\n",
    "plt.ylabel(r'$(mag_{\\rm meas} - mag_{\\rm fake})$ (mmag)')\n",
    "plt.xlim(15.2, 23.3)\n",
    "plt.ylim(-48, 48)\n",
    "plt.minorticks_on()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a5512f-a74c-497b-8624-ed904505ca65",
   "metadata": {},
   "source": [
    "Looks good! (Note that the y-axis is showing residuals in _millimags_.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba6a7f9-a07e-49a1-903c-b3324589f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(14, 7))\n",
    "plt.sca(ax[0])  # set the first axis as current\n",
    "display1 = afwDisplay.Display(frame=fig)\n",
    "display1.scale('linear', 'zscale')\n",
    "display1.mtv(calexp_orig_r.image)\n",
    "plt.title('original image')\n",
    "plt.xlim(1000, 2500)\n",
    "plt.ylim(300, 1800)\n",
    "plt.sca(ax[1])  # set the second axis as current\n",
    "display2 = afwDisplay.Display(frame=fig)\n",
    "display2.scale('linear', 'zscale')\n",
    "display2.mtv(calexp_new_r.image)\n",
    "# display2.mtv(image0)\n",
    "plt.title('with fake stars')\n",
    "plt.xlim(1000, 2500)\n",
    "plt.ylim(300, 1800)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f35eb2-054c-4186-99a8-a35e95e4a277",
   "metadata": {},
   "source": [
    "Ideas for further exploration:\n",
    "\n",
    "- Inject stars using a realistic stellar population (i.e., get colors and a luminosity function from isochrones).\n",
    "- Inject galaxies or other objects.\n",
    "- Inject periodic variables into a set of overlapping visit images (using their time of observation to determine the input phase, and thus magnitude, for each image).\n",
    "- Test completeness of detection/measurement (will need to inject stars over a variety of magnitudes and colors, and probably many times over to build up a large enough statistical sample).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104b9750-4926-4073-8384-3ef1ed54ba80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
